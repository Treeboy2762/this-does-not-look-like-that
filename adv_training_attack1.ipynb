{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head-On-Stomach Experiment: Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classes used:  200\n",
      "100%|█████████████████████████████████████| 11788/11788 [10:21<00:00, 18.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Setup the dataset\n",
    "# You might have to adjust the data_path in settings.py and setup.py files\n",
    "!python src/data/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b4aaa4728d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# External Imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "\n",
    "# GitLab Code imports\n",
    "sys.path.insert(0, './src/models/')\n",
    "import src.training.train_and_test as tnt\n",
    "from src.data.preprocess import mean, std\n",
    "from settings import img_size, test_batch_size\n",
    "from src.data.customdataset import CustomImageFolder\n",
    "from src.utils.local_analysis import LocalAnalysis\n",
    "from src.utils.helpers import find_high_activation_crop, get_all_xy\n",
    "\n",
    "from settings import colab, username\n",
    "\n",
    "# Random Seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "# You might have to change this directory path\n",
    "directory = \"/scratch/PPNet/datasets/cub200_cropped/\"\n",
    "test_dir = directory + \"test_cropped/\"\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_classified_images(\n",
    "    model,\n",
    "    dataloader,\n",
    "    class_specific=True,\n",
    "    log=print\n",
    "):\n",
    "    \"\"\"\n",
    "    Get indices of correctly classified images.\n",
    "    \"\"\"\n",
    "    log(\"\\ttest\")\n",
    "    model.eval()\n",
    "\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    correct_idx = []\n",
    "    \n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        input = image.cuda()\n",
    "        target = label.cuda()\n",
    "\n",
    "        output, min_distances = model(input)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct_idx.extend((n_examples + (predicted == target).nonzero().squeeze(1).cpu().numpy()).tolist())\n",
    "\n",
    "        n_examples += target.size(0)\n",
    "        n_correct += (predicted == target).sum().item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del predicted\n",
    "\n",
    "    end = time.time()\n",
    "    log(\"\\ttime: \\t{0}\".format(end - start))\n",
    "    log(\"\\taccu: \\t{0}%\".format(n_correct / n_examples * 100))\n",
    "    return correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from /cluster/scratch/rarade/PPNet/saved_models/resnet34/105/10_0push0.2416.pth\n",
      "model base architecture: resnet34\n",
      "experiment run: 105\n",
      "Prototypes are chosen from 200 number of classes.\n",
      "Their class identities are: [  0   0   0 ... 199 199 199]\n",
      "All prototypes connect most strongly to their respective classes.\n",
      "\n",
      "Accuracy on test data set.\n",
      "\ttest\n",
      "\ttime: \t8.325947999954224\n",
      "\taccu: \t58.802209181912325%\n"
     ]
    }
   ],
   "source": [
    "# Select Network, and specify Experiment run\n",
    "base_architecture = 'resnet34' #'resnet34', 'vgg19'\n",
    "experiment_run = '105'\n",
    "\n",
    "# Model directory\n",
    "# load the model\n",
    "if colab:\n",
    "    load_model_dir = '/content/PPNet/saved_models/{}/{}/'.format(base_architecture, experiment_run)\n",
    "else:\n",
    "    load_model_dir = '/cluster/scratch/{}/PPNet/saved_models/{}/{}/'.format(username, base_architecture, \n",
    "                                                                            experiment_run)\n",
    "load_model_name = '10_0push0.2416.pth'\n",
    "\n",
    "la1 = LocalAnalysis(load_model_dir, load_model_name, \"\", attack=1)\n",
    "img_size = la1.img_size\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((img_size, img_size)),\n",
    "   transforms.ToTensor(),\n",
    "   la1.normalize\n",
    "])\n",
    "\n",
    "print(\"\\nAccuracy on test data set.\")\n",
    "corr_rob = get_correct_classified_images(model=la1.ppnet_multi, dataloader=test_loader, \n",
    "                                         class_specific=la1.class_specific, \n",
    "                                         log=la1.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from /cluster/scratch/rarade/PPNet/saved_models/resnet34/004/10_18push0.7958.pth\n",
      "model base architecture: resnet34\n",
      "experiment run: 004\n",
      "Prototypes are chosen from 200 number of classes.\n",
      "Their class identities are: [  0   0   0 ... 199 199 199]\n",
      "WARNING: Not all prototypes connect most strongly to their respective classes.\n",
      "\n",
      "Accuracy on test data set.\n",
      "\ttest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/rarade/torch/lib64/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'model.PPNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/cluster/home/rarade/torch/lib64/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'resnet_features.ResNet_features' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttime: \t8.280785322189331\n",
      "\taccu: \t79.58232654470142%\n"
     ]
    }
   ],
   "source": [
    "# Select Network, and specify Experiment run\n",
    "base_architecture = 'resnet34' #'resnet34', 'vgg19'\n",
    "experiment_run = '004'\n",
    "\n",
    "# Model directory\n",
    "# load the model\n",
    "if colab:\n",
    "    load_model_dir = '/content/PPNet/saved_models/{}/{}/'.format(base_architecture, experiment_run)\n",
    "else:\n",
    "    load_model_dir = '/cluster/scratch/{}/PPNet/saved_models/{}/{}/'.format(username, base_architecture, \n",
    "                                                                            experiment_run)\n",
    "load_model_name = '10_18push0.7958.pth'\n",
    "\n",
    "la2 = LocalAnalysis(load_model_dir, load_model_name, \"\", attack=1)\n",
    "\n",
    "print(\"\\nAccuracy on test data set.\")\n",
    "corr_std = get_correct_classified_images(model=la2.ppnet_multi, dataloader=test_loader, \n",
    "                                         class_specific=la2.class_specific, \n",
    "                                         log=la2.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 images to test.\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 200\n",
    "\n",
    "corr_idx = np.array(list(set(corr_std) & set(corr_rob)))\n",
    "np.random.seed(0)\n",
    "corr_idx = corr_idx[np.random.choice(len(corr_idx), NUM_SAMPLES, replace=False)].tolist()\n",
    "print ('{} images to test.'.format(len(corr_idx)))\n",
    "\n",
    "correct_subset = torch.utils.data.Subset(test_dataset, corr_idx)\n",
    "correct_loader = torch.utils.data.DataLoader(\n",
    "    correct_subset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(\n",
    "    la, \n",
    "    dataloader, \n",
    "    log=print,\n",
    "    grid=7\n",
    "):\n",
    "    la.ppnet_multi.eval()\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_attacked = 0\n",
    "    n_errors = 0\n",
    "    \n",
    "    for image, label in tqdm(dataloader):\n",
    "        input = image.cuda()\n",
    "        target = label.item()\n",
    "          \n",
    "        try:    \n",
    "            with HiddenPrints():\n",
    "                sorted_indices_act, prototype_activation_patterns, _ = la.local_analysis(\n",
    "                    input, target, show_images=False, max_prototypes=1\n",
    "                )\n",
    "\n",
    "            idx = 0\n",
    "            PID = sorted_indices_act[-1].item()\n",
    "            activation_pattern = prototype_activation_patterns[idx][PID].detach().cpu().numpy()\n",
    "            upsampled_activation_pattern = cv2.resize(\n",
    "                activation_pattern, dsize=(la.img_size, la.img_size), interpolation=cv2.INTER_CUBIC\n",
    "            )\n",
    "            high_act_patch_indices = find_high_activation_crop(upsampled_activation_pattern)\n",
    "            step = img_size // grid\n",
    "            act_loc = [\n",
    "                high_act_patch_indices[0] // step,\n",
    "                high_act_patch_indices[1] // step,\n",
    "                high_act_patch_indices[2] // step,\n",
    "                high_act_patch_indices[3] // step,\n",
    "            ]\n",
    "            act_loc = [\n",
    "                yx\n",
    "                for yx in itertools.product(\n",
    "                    np.arange(act_loc[0], act_loc[1]), np.arange(act_loc[2], act_loc[3])\n",
    "                )\n",
    "            ]\n",
    "            loc = list(set([i for i in itertools.product(np.arange(0, grid), np.arange(0, grid))]) - set(act_loc))\n",
    "\n",
    "            with HiddenPrints():\n",
    "                image_perturbed, _ = la.attack1(input, loc=loc, i=PID, idx=0, show_images=False)\n",
    "\n",
    "                _, prototype_activation_patterns, _ = la.local_analysis(\n",
    "                    la.normalize(image_perturbed.squeeze(0)).unsqueeze(0), \n",
    "                    target, show_images=False, max_prototypes=2000, pid=PID\n",
    "                )\n",
    "\n",
    "            p_act = prototype_activation_patterns[idx][PID]\n",
    "            act_sim = torch.zeros(len(act_loc)).cuda()\n",
    "            for i, l in enumerate(act_loc):\n",
    "                act_sim[i] = p_act[l[0], l[1]]\n",
    "            \n",
    "            if torch.max(p_act) > torch.max(act_sim):\n",
    "                n_attacked += 1\n",
    "            n_examples += 1\n",
    "            \n",
    "            del input\n",
    "            del target\n",
    "            del image_perturbed\n",
    "            del prototype_activation_patterns\n",
    "        except:\n",
    "            n_errors += 1\n",
    "            continue\n",
    "                \n",
    "    end = time.time()\n",
    "    log(\"\\ttime: \\t\\t\\t{0}\".format(end - start))\n",
    "    log(\"\\tattack success rate: \\t{0}%\".format(n_attacked / n_examples * 100))\n",
    "    \n",
    "    return n_attacked / n_examples, n_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard trained model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248a407741114aaba8b13172594abc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttime: \t\t\t746.9579815864563\n",
      "\tattack success rate: \t79.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Standard trained model.')\n",
    "analyze(la2, correct_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarially trained model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ce541d33a6429ca56c838d836b9b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttime: \t\t\t744.8163366317749\n",
      "\tattack success rate: \t34.17085427135678%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3417085427135678"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Adversarially trained model.')\n",
    "analyze(la1, correct_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /scratch/PPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
