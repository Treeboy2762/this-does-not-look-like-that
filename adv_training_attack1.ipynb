{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head-On-Stomach Experiment: Success Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the dataset\n",
    "# You might have to adjust the data_path in settings.py and setup.py files\n",
    "!python src/data/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Imports\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "# GitLab Code imports\n",
    "sys.path.insert(0, './src/models/')\n",
    "import src.training.train_and_test as tnt\n",
    "from src.data.preprocess import mean, std\n",
    "from settings import img_size, test_batch_size\n",
    "from src.data.customdataset import CustomImageFolder\n",
    "from src.data.preprocess import mean, std, undo_preprocess_input_function\n",
    "from src.utils.local_analysis import LocalAnalysis\n",
    "from src.utils.helpers import find_high_activation_crop, get_all_xy\n",
    "\n",
    "from settings import colab, username\n",
    "\n",
    "# Random Seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "# You might have to change this directory path\n",
    "directory = \"/scratch/PPNet/datasets/cub200_cropped/\"\n",
    "test_dir = directory + \"test_cropped/\"\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    test_dir,\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(size=(img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_classified_images(\n",
    "    model,\n",
    "    dataloader,\n",
    "    class_specific=True,\n",
    "    log=print\n",
    "):\n",
    "    \"\"\"\n",
    "    Get indices of correctly classified images.\n",
    "    \"\"\"\n",
    "    log(\"\\ttest\")\n",
    "    model.eval()\n",
    "\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_correct = 0\n",
    "    n_batches = 0\n",
    "    correct_idx = []\n",
    "    \n",
    "    for i, (image, label) in enumerate(dataloader):\n",
    "        input = image.cuda()\n",
    "        target = label.cuda()\n",
    "\n",
    "        output, min_distances = model(input)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct_idx.extend((n_examples + (predicted == target).nonzero().squeeze(1).cpu().numpy()).tolist())\n",
    "\n",
    "        n_examples += target.size(0)\n",
    "        n_correct += (predicted == target).sum().item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del predicted\n",
    "\n",
    "    end = time.time()\n",
    "    log(\"\\ttime: \\t{0}\".format(end - start))\n",
    "    log(\"\\taccu: \\t{0}%\".format(n_correct / n_examples * 100))\n",
    "    return correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Network, and specify Experiment run\n",
    "base_architecture = 'resnet34' #'resnet34', 'vgg19'\n",
    "experiment_run = '105'\n",
    "\n",
    "# Model directory\n",
    "# load the model\n",
    "if colab:\n",
    "    load_model_dir = '/content/PPNet/saved_models/{}/{}/'.format(base_architecture, experiment_run)\n",
    "else:\n",
    "    load_model_dir = '/cluster/scratch/{}/PPNet/saved_models/{}/{}/'.format(username, base_architecture, \n",
    "                                                                            experiment_run)\n",
    "load_model_name = '10_0push0.2416.pth'\n",
    "\n",
    "la1 = LocalAnalysis(load_model_dir, load_model_name, \"\", attack=1)\n",
    "img_size = la1.img_size\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((img_size, img_size)),\n",
    "   transforms.ToTensor(),\n",
    "   la1.normalize\n",
    "])\n",
    "\n",
    "print(\"\\nAccuracy on test data set.\")\n",
    "corr_rob = get_correct_classified_images(model=la1.ppnet_multi, dataloader=test_loader, \n",
    "                                         class_specific=la1.class_specific, \n",
    "                                         log=la1.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select Network, and specify Experiment run\n",
    "base_architecture = 'resnet34' #'resnet34', 'vgg19'\n",
    "experiment_run = '004'\n",
    "\n",
    "# Model directory\n",
    "# load the model\n",
    "if colab:\n",
    "    load_model_dir = '/content/PPNet/saved_models/{}/{}/'.format(base_architecture, experiment_run)\n",
    "else:\n",
    "    load_model_dir = '/cluster/scratch/{}/PPNet/saved_models/{}/{}/'.format(username, base_architecture, \n",
    "                                                                            experiment_run)\n",
    "load_model_name = '10_18push0.7958.pth'\n",
    "\n",
    "la2 = LocalAnalysis(load_model_dir, load_model_name, \"\", attack=1)\n",
    "\n",
    "print(\"\\nAccuracy on test data set.\")\n",
    "corr_std = get_correct_classified_images(model=la2.ppnet_multi, dataloader=test_loader, \n",
    "                                         class_specific=la2.class_specific, \n",
    "                                         log=la2.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 200\n",
    "\n",
    "corr_idx = np.array(list(set(corr_std) & set(corr_rob)))\n",
    "np.random.seed(0)\n",
    "corr_idx = corr_idx[np.random.choice(len(corr_idx), NUM_SAMPLES+50, replace=False)].tolist()\n",
    "print ('{} images to test.'.format(len(corr_idx)))\n",
    "\n",
    "correct_subset = torch.utils.data.Subset(test_dataset, corr_idx)\n",
    "correct_loader = torch.utils.data.DataLoader(\n",
    "    correct_subset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(\n",
    "    la, \n",
    "    dataloader, \n",
    "    log=print,\n",
    "    grid=7,\n",
    "    max_prototyopes=5\n",
    "):\n",
    "    la.ppnet_multi.eval()\n",
    "    start = time.time()\n",
    "    n_examples = 0\n",
    "    n_attacked = 0\n",
    "    errors = []\n",
    "    \n",
    "    pbar = tqdm(dataloader)\n",
    "    for k, (image, label) in enumerate(pbar):\n",
    "        input = image.cuda()\n",
    "        target = label.item()\n",
    "          \n",
    "        try:\n",
    "            with HiddenPrints():\n",
    "                sorted_indices_act, prototype_activation_patterns, _ = la.local_analysis(\n",
    "                    input, target, show_images=False, max_prototypes=1\n",
    "                )\n",
    "\n",
    "            idx, pindex = 0, 1\n",
    "            while pindex <= max_prototyopes:\n",
    "                PID = sorted_indices_act[-pindex].item()\n",
    "                activation_pattern = prototype_activation_patterns[idx][PID].detach().cpu().numpy()\n",
    "                upsampled_activation_pattern = cv2.resize(\n",
    "                    activation_pattern, dsize=(la.img_size, la.img_size), interpolation=cv2.INTER_CUBIC\n",
    "                )\n",
    "                high_act_patch_indices = find_high_activation_crop(upsampled_activation_pattern)\n",
    "                step = img_size // grid\n",
    "                act_loc = [\n",
    "                    high_act_patch_indices[0] // step,\n",
    "                    high_act_patch_indices[1] // step,\n",
    "                    high_act_patch_indices[2] // step,\n",
    "                    high_act_patch_indices[3] // step,\n",
    "                ]\n",
    "                act_loc = [\n",
    "                    yx\n",
    "                    for yx in itertools.product(\n",
    "                        np.arange(act_loc[0], min(act_loc[1]+1, grid)), np.arange(act_loc[2], min(act_loc[3]+1, grid))\n",
    "                    )\n",
    "                ]\n",
    "                loc = list(set([i for i in itertools.product(np.arange(0, grid), np.arange(0, grid))]) - set(act_loc))\n",
    "\n",
    "                with HiddenPrints():\n",
    "                    image_perturbed, _ = la.attack1(input, loc=loc, i=PID, idx=0, show_images=False)\n",
    "\n",
    "                    _, prototype_activation_patterns, _ = la.local_analysis(\n",
    "                        la.normalize(image_perturbed.squeeze(0)).unsqueeze(0), \n",
    "                        target, show_images=False, max_prototypes=2000, pid=PID\n",
    "                    )\n",
    "\n",
    "                p_act = prototype_activation_patterns[idx][PID]\n",
    "                act_sim = torch.zeros(len(act_loc)).cuda()\n",
    "                for i, l in enumerate(act_loc):\n",
    "                    act_sim[i] = p_act[l[0], l[1]]\n",
    "\n",
    "                if torch.max(p_act) > torch.max(act_sim):\n",
    "                    n_attacked += 1\n",
    "                    break\n",
    "                else:\n",
    "                    pindex += 1\n",
    "            n_examples += 1\n",
    "        except:\n",
    "            errors.append(k)\n",
    "        \n",
    "        pbar.set_postfix({'Success rate': f'{n_attacked}/{n_examples}'})\n",
    "        if n_examples == NUM_SAMPLES:\n",
    "            print (f'Evaluation on {n_examples} samples completed.')\n",
    "            break\n",
    "        \n",
    "    end = time.time()\n",
    "    log(\"\\ttime: \\t\\t\\t{0}\".format(end - start))\n",
    "    log(\"\\tattack success rate: \\t{0}%\".format(n_attacked / n_examples * 100))\n",
    "    return n_attacked / n_examples, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print ('Standard trained model.')\n",
    "acc, errors = analyze(la2, correct_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Adversarially trained model.')\n",
    "acc, errors = analyze(la1, correct_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /scratch/PPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
